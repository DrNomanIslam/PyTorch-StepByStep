{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as fun\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pd.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
    "X = dataframe.values[:,0:13]\n",
    "Y = dataframe.values[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=(X - np.mean(X)) / np.std(X)\n",
    "Y=(Y - np.mean(Y)) / np.std(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensor from numpy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = torch.from_numpy(X).float()\n",
    "y = torch.unsqueeze(torch.from_numpy(Y).float(),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden1, n_hidden2,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_feature, n_hidden1)   # hidden layer 1\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden1, n_hidden2)   # hidden layer 2\n",
    "        self.predict = torch.nn.Linear(n_hidden2, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fun.relu(self.hidden1(x))      # activation function for hidden layer\n",
    "        x = fun.relu(self.hidden2(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create the model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Net(n_feature=13, n_hidden1=25, n_hidden2=25, n_output=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Loss:  tensor(1.0222)\n",
      "Epoch:  1  Loss:  tensor(0.9959)\n",
      "Epoch:  2  Loss:  tensor(0.9724)\n",
      "Epoch:  3  Loss:  tensor(0.9469)\n",
      "Epoch:  4  Loss:  tensor(0.9153)\n",
      "Epoch:  5  Loss:  tensor(0.8897)\n",
      "Epoch:  6  Loss:  tensor(0.9070)\n",
      "Epoch:  7  Loss:  tensor(1.1540)\n",
      "Epoch:  8  Loss:  tensor(1.4483)\n",
      "Epoch:  9  Loss:  tensor(1.1009)\n",
      "Epoch:  10  Loss:  tensor(0.9791)\n",
      "Epoch:  11  Loss:  tensor(0.9431)\n",
      "Epoch:  12  Loss:  tensor(0.9062)\n",
      "Epoch:  13  Loss:  tensor(0.8667)\n",
      "Epoch:  14  Loss:  tensor(0.8280)\n",
      "Epoch:  15  Loss:  tensor(0.7976)\n",
      "Epoch:  16  Loss:  tensor(0.7781)\n",
      "Epoch:  17  Loss:  tensor(0.7687)\n",
      "Epoch:  18  Loss:  tensor(0.7725)\n",
      "Epoch:  19  Loss:  tensor(0.8483)\n",
      "Epoch:  20  Loss:  tensor(1.3222)\n",
      "Epoch:  21  Loss:  tensor(1.5430)\n",
      "Epoch:  22  Loss:  tensor(1.0070)\n",
      "Epoch:  23  Loss:  tensor(0.9877)\n",
      "Epoch:  24  Loss:  tensor(0.9748)\n",
      "Epoch:  25  Loss:  tensor(0.9587)\n",
      "Epoch:  26  Loss:  tensor(0.9369)\n",
      "Epoch:  27  Loss:  tensor(0.9076)\n",
      "Epoch:  28  Loss:  tensor(0.8709)\n",
      "Epoch:  29  Loss:  tensor(0.8318)\n",
      "Epoch:  30  Loss:  tensor(0.7964)\n",
      "Epoch:  31  Loss:  tensor(0.7727)\n",
      "Epoch:  32  Loss:  tensor(0.7612)\n",
      "Epoch:  33  Loss:  tensor(0.7560)\n",
      "Epoch:  34  Loss:  tensor(0.7530)\n",
      "Epoch:  35  Loss:  tensor(0.7519)\n",
      "Epoch:  36  Loss:  tensor(0.7610)\n",
      "Epoch:  37  Loss:  tensor(0.8170)\n",
      "Epoch:  38  Loss:  tensor(0.9503)\n",
      "Epoch:  39  Loss:  tensor(1.2063)\n",
      "Epoch:  40  Loss:  tensor(0.8399)\n",
      "Epoch:  41  Loss:  tensor(0.7955)\n",
      "Epoch:  42  Loss:  tensor(0.7697)\n",
      "Epoch:  43  Loss:  tensor(0.7583)\n",
      "Epoch:  44  Loss:  tensor(0.7540)\n",
      "Epoch:  45  Loss:  tensor(0.7517)\n",
      "Epoch:  46  Loss:  tensor(0.7493)\n",
      "Epoch:  47  Loss:  tensor(0.7470)\n",
      "Epoch:  48  Loss:  tensor(0.7447)\n",
      "Epoch:  49  Loss:  tensor(0.7425)\n",
      "Epoch:  50  Loss:  tensor(0.7395)\n",
      "Epoch:  51  Loss:  tensor(0.7366)\n",
      "Epoch:  52  Loss:  tensor(0.7358)\n",
      "Epoch:  53  Loss:  tensor(0.7383)\n",
      "Epoch:  54  Loss:  tensor(0.7497)\n",
      "Epoch:  55  Loss:  tensor(0.8006)\n",
      "Epoch:  56  Loss:  tensor(0.9492)\n",
      "Epoch:  57  Loss:  tensor(0.9113)\n",
      "Epoch:  58  Loss:  tensor(0.9294)\n",
      "Epoch:  59  Loss:  tensor(0.7688)\n",
      "Epoch:  60  Loss:  tensor(0.7463)\n",
      "Epoch:  61  Loss:  tensor(0.7412)\n",
      "Epoch:  62  Loss:  tensor(0.7389)\n",
      "Epoch:  63  Loss:  tensor(0.7374)\n",
      "Epoch:  64  Loss:  tensor(0.7368)\n",
      "Epoch:  65  Loss:  tensor(0.7369)\n",
      "Epoch:  66  Loss:  tensor(0.7401)\n",
      "Epoch:  67  Loss:  tensor(0.7467)\n",
      "Epoch:  68  Loss:  tensor(0.7730)\n",
      "Epoch:  69  Loss:  tensor(0.7977)\n",
      "Epoch:  70  Loss:  tensor(0.8635)\n",
      "Epoch:  71  Loss:  tensor(0.8207)\n",
      "Epoch:  72  Loss:  tensor(0.8183)\n",
      "Epoch:  73  Loss:  tensor(0.7647)\n",
      "Epoch:  74  Loss:  tensor(0.7579)\n",
      "Epoch:  75  Loss:  tensor(0.7528)\n",
      "Epoch:  76  Loss:  tensor(0.7563)\n",
      "Epoch:  77  Loss:  tensor(0.7578)\n",
      "Epoch:  78  Loss:  tensor(0.7682)\n",
      "Epoch:  79  Loss:  tensor(0.7717)\n",
      "Epoch:  80  Loss:  tensor(0.7891)\n",
      "Epoch:  81  Loss:  tensor(0.7800)\n",
      "Epoch:  82  Loss:  tensor(0.7887)\n",
      "Epoch:  83  Loss:  tensor(0.7717)\n",
      "Epoch:  84  Loss:  tensor(0.7719)\n",
      "Epoch:  85  Loss:  tensor(0.7564)\n",
      "Epoch:  86  Loss:  tensor(0.7533)\n",
      "Epoch:  87  Loss:  tensor(0.7489)\n",
      "Epoch:  88  Loss:  tensor(0.7558)\n",
      "Epoch:  89  Loss:  tensor(0.7578)\n",
      "Epoch:  90  Loss:  tensor(0.7734)\n",
      "Epoch:  91  Loss:  tensor(0.7756)\n",
      "Epoch:  92  Loss:  tensor(0.7803)\n",
      "Epoch:  93  Loss:  tensor(0.7721)\n",
      "Epoch:  94  Loss:  tensor(0.7681)\n",
      "Epoch:  95  Loss:  tensor(0.7554)\n",
      "Epoch:  96  Loss:  tensor(0.7494)\n",
      "Epoch:  97  Loss:  tensor(0.7445)\n",
      "Epoch:  98  Loss:  tensor(0.7453)\n",
      "Epoch:  99  Loss:  tensor(0.7469)\n",
      "Epoch:  100  Loss:  tensor(0.7533)\n",
      "Epoch:  101  Loss:  tensor(0.7594)\n",
      "Epoch:  102  Loss:  tensor(0.7731)\n",
      "Epoch:  103  Loss:  tensor(0.7806)\n",
      "Epoch:  104  Loss:  tensor(0.7699)\n",
      "Epoch:  105  Loss:  tensor(0.7586)\n",
      "Epoch:  106  Loss:  tensor(0.7473)\n",
      "Epoch:  107  Loss:  tensor(0.7407)\n",
      "Epoch:  108  Loss:  tensor(0.7441)\n",
      "Epoch:  109  Loss:  tensor(0.7462)\n",
      "Epoch:  110  Loss:  tensor(0.7501)\n",
      "Epoch:  111  Loss:  tensor(0.7574)\n",
      "Epoch:  112  Loss:  tensor(0.7548)\n",
      "Epoch:  113  Loss:  tensor(0.7556)\n",
      "Epoch:  114  Loss:  tensor(0.7526)\n",
      "Epoch:  115  Loss:  tensor(0.7559)\n",
      "Epoch:  116  Loss:  tensor(0.7460)\n",
      "Epoch:  117  Loss:  tensor(0.7451)\n",
      "Epoch:  118  Loss:  tensor(0.7403)\n",
      "Epoch:  119  Loss:  tensor(0.7407)\n",
      "Epoch:  120  Loss:  tensor(0.7378)\n",
      "Epoch:  121  Loss:  tensor(0.7430)\n",
      "Epoch:  122  Loss:  tensor(0.7432)\n",
      "Epoch:  123  Loss:  tensor(0.7547)\n",
      "Epoch:  124  Loss:  tensor(0.7570)\n",
      "Epoch:  125  Loss:  tensor(0.7765)\n",
      "Epoch:  126  Loss:  tensor(0.7579)\n",
      "Epoch:  127  Loss:  tensor(0.7565)\n",
      "Epoch:  128  Loss:  tensor(0.7392)\n",
      "Epoch:  129  Loss:  tensor(0.7372)\n",
      "Epoch:  130  Loss:  tensor(0.7308)\n",
      "Epoch:  131  Loss:  tensor(0.7327)\n",
      "Epoch:  132  Loss:  tensor(0.7300)\n",
      "Epoch:  133  Loss:  tensor(0.7370)\n",
      "Epoch:  134  Loss:  tensor(0.7422)\n",
      "Epoch:  135  Loss:  tensor(0.7653)\n",
      "Epoch:  136  Loss:  tensor(0.7540)\n",
      "Epoch:  137  Loss:  tensor(0.7617)\n",
      "Epoch:  138  Loss:  tensor(0.7446)\n",
      "Epoch:  139  Loss:  tensor(0.7502)\n",
      "Epoch:  140  Loss:  tensor(0.7369)\n",
      "Epoch:  141  Loss:  tensor(0.7391)\n",
      "Epoch:  142  Loss:  tensor(0.7296)\n",
      "Epoch:  143  Loss:  tensor(0.7348)\n",
      "Epoch:  144  Loss:  tensor(0.7328)\n",
      "Epoch:  145  Loss:  tensor(0.7412)\n",
      "Epoch:  146  Loss:  tensor(0.7373)\n",
      "Epoch:  147  Loss:  tensor(0.7534)\n",
      "Epoch:  148  Loss:  tensor(0.7469)\n",
      "Epoch:  149  Loss:  tensor(0.7656)\n",
      "Epoch:  150  Loss:  tensor(0.7422)\n",
      "Epoch:  151  Loss:  tensor(0.7449)\n",
      "Epoch:  152  Loss:  tensor(0.7307)\n",
      "Epoch:  153  Loss:  tensor(0.7345)\n",
      "Epoch:  154  Loss:  tensor(0.7247)\n",
      "Epoch:  155  Loss:  tensor(0.7309)\n",
      "Epoch:  156  Loss:  tensor(0.7268)\n",
      "Epoch:  157  Loss:  tensor(0.7373)\n",
      "Epoch:  158  Loss:  tensor(0.7354)\n",
      "Epoch:  159  Loss:  tensor(0.7509)\n",
      "Epoch:  160  Loss:  tensor(0.7415)\n",
      "Epoch:  161  Loss:  tensor(0.7603)\n",
      "Epoch:  162  Loss:  tensor(0.7340)\n",
      "Epoch:  163  Loss:  tensor(0.7327)\n",
      "Epoch:  164  Loss:  tensor(0.7254)\n",
      "Epoch:  165  Loss:  tensor(0.7332)\n",
      "Epoch:  166  Loss:  tensor(0.7235)\n",
      "Epoch:  167  Loss:  tensor(0.7307)\n",
      "Epoch:  168  Loss:  tensor(0.7257)\n",
      "Epoch:  169  Loss:  tensor(0.7384)\n",
      "Epoch:  170  Loss:  tensor(0.7311)\n",
      "Epoch:  171  Loss:  tensor(0.7478)\n",
      "Epoch:  172  Loss:  tensor(0.7368)\n",
      "Epoch:  173  Loss:  tensor(0.7527)\n",
      "Epoch:  174  Loss:  tensor(0.7305)\n",
      "Epoch:  175  Loss:  tensor(0.7322)\n",
      "Epoch:  176  Loss:  tensor(0.7251)\n",
      "Epoch:  177  Loss:  tensor(0.7334)\n",
      "Epoch:  178  Loss:  tensor(0.7231)\n",
      "Epoch:  179  Loss:  tensor(0.7330)\n",
      "Epoch:  180  Loss:  tensor(0.7240)\n",
      "Epoch:  181  Loss:  tensor(0.7333)\n",
      "Epoch:  182  Loss:  tensor(0.7258)\n",
      "Epoch:  183  Loss:  tensor(0.7381)\n",
      "Epoch:  184  Loss:  tensor(0.7283)\n",
      "Epoch:  185  Loss:  tensor(0.7430)\n",
      "Epoch:  186  Loss:  tensor(0.7287)\n",
      "Epoch:  187  Loss:  tensor(0.7405)\n",
      "Epoch:  188  Loss:  tensor(0.7271)\n",
      "Epoch:  189  Loss:  tensor(0.7361)\n",
      "Epoch:  190  Loss:  tensor(0.7218)\n",
      "Epoch:  191  Loss:  tensor(0.7254)\n",
      "Epoch:  192  Loss:  tensor(0.7167)\n",
      "Epoch:  193  Loss:  tensor(0.7214)\n",
      "Epoch:  194  Loss:  tensor(0.7127)\n",
      "Epoch:  195  Loss:  tensor(0.7157)\n",
      "Epoch:  196  Loss:  tensor(0.7101)\n",
      "Epoch:  197  Loss:  tensor(0.7155)\n",
      "Epoch:  198  Loss:  tensor(0.7125)\n",
      "Epoch:  199  Loss:  tensor(0.7207)\n",
      "Epoch:  200  Loss:  tensor(0.7188)\n",
      "Epoch:  201  Loss:  tensor(0.7386)\n",
      "Epoch:  202  Loss:  tensor(0.7270)\n",
      "Epoch:  203  Loss:  tensor(0.7520)\n",
      "Epoch:  204  Loss:  tensor(0.7313)\n",
      "Epoch:  205  Loss:  tensor(0.7413)\n",
      "Epoch:  206  Loss:  tensor(0.7352)\n",
      "Epoch:  207  Loss:  tensor(0.7560)\n",
      "Epoch:  208  Loss:  tensor(0.7296)\n",
      "Epoch:  209  Loss:  tensor(0.7284)\n",
      "Epoch:  210  Loss:  tensor(0.7283)\n",
      "Epoch:  211  Loss:  tensor(0.7449)\n",
      "Epoch:  212  Loss:  tensor(0.7207)\n",
      "Epoch:  213  Loss:  tensor(0.7232)\n",
      "Epoch:  214  Loss:  tensor(0.7202)\n",
      "Epoch:  215  Loss:  tensor(0.7308)\n",
      "Epoch:  216  Loss:  tensor(0.7225)\n",
      "Epoch:  217  Loss:  tensor(0.7422)\n",
      "Epoch:  218  Loss:  tensor(0.7263)\n",
      "Epoch:  219  Loss:  tensor(0.7328)\n",
      "Epoch:  220  Loss:  tensor(0.7244)\n",
      "Epoch:  221  Loss:  tensor(0.7350)\n",
      "Epoch:  222  Loss:  tensor(0.7221)\n",
      "Epoch:  223  Loss:  tensor(0.7340)\n",
      "Epoch:  224  Loss:  tensor(0.7219)\n",
      "Epoch:  225  Loss:  tensor(0.7281)\n",
      "Epoch:  226  Loss:  tensor(0.7169)\n",
      "Epoch:  227  Loss:  tensor(0.7202)\n",
      "Epoch:  228  Loss:  tensor(0.7111)\n",
      "Epoch:  229  Loss:  tensor(0.7156)\n",
      "Epoch:  230  Loss:  tensor(0.7103)\n",
      "Epoch:  231  Loss:  tensor(0.7194)\n",
      "Epoch:  232  Loss:  tensor(0.7159)\n",
      "Epoch:  233  Loss:  tensor(0.7257)\n",
      "Epoch:  234  Loss:  tensor(0.7204)\n",
      "Epoch:  235  Loss:  tensor(0.7393)\n",
      "Epoch:  236  Loss:  tensor(0.7293)\n",
      "Epoch:  237  Loss:  tensor(0.7495)\n",
      "Epoch:  238  Loss:  tensor(0.7241)\n",
      "Epoch:  239  Loss:  tensor(0.7267)\n",
      "Epoch:  240  Loss:  tensor(0.7189)\n",
      "Epoch:  241  Loss:  tensor(0.7246)\n",
      "Epoch:  242  Loss:  tensor(0.7124)\n",
      "Epoch:  243  Loss:  tensor(0.7215)\n",
      "Epoch:  244  Loss:  tensor(0.7156)\n",
      "Epoch:  245  Loss:  tensor(0.7235)\n",
      "Epoch:  246  Loss:  tensor(0.7170)\n",
      "Epoch:  247  Loss:  tensor(0.7288)\n",
      "Epoch:  248  Loss:  tensor(0.7218)\n",
      "Epoch:  249  Loss:  tensor(0.7370)\n",
      "Epoch:  250  Loss:  tensor(0.7242)\n",
      "Epoch:  251  Loss:  tensor(0.7357)\n",
      "Epoch:  252  Loss:  tensor(0.7170)\n",
      "Epoch:  253  Loss:  tensor(0.7256)\n",
      "Epoch:  254  Loss:  tensor(0.7133)\n",
      "Epoch:  255  Loss:  tensor(0.7159)\n",
      "Epoch:  256  Loss:  tensor(0.7056)\n",
      "Epoch:  257  Loss:  tensor(0.7103)\n",
      "Epoch:  258  Loss:  tensor(0.7101)\n",
      "Epoch:  259  Loss:  tensor(0.7179)\n",
      "Epoch:  260  Loss:  tensor(0.7157)\n",
      "Epoch:  261  Loss:  tensor(0.7273)\n",
      "Epoch:  262  Loss:  tensor(0.7209)\n",
      "Epoch:  263  Loss:  tensor(0.7354)\n",
      "Epoch:  264  Loss:  tensor(0.7231)\n",
      "Epoch:  265  Loss:  tensor(0.7352)\n",
      "Epoch:  266  Loss:  tensor(0.7168)\n",
      "Epoch:  267  Loss:  tensor(0.7222)\n",
      "Epoch:  268  Loss:  tensor(0.7078)\n",
      "Epoch:  269  Loss:  tensor(0.7096)\n",
      "Epoch:  270  Loss:  tensor(0.7046)\n",
      "Epoch:  271  Loss:  tensor(0.7077)\n",
      "Epoch:  272  Loss:  tensor(0.7051)\n",
      "Epoch:  273  Loss:  tensor(0.7133)\n",
      "Epoch:  274  Loss:  tensor(0.7105)\n",
      "Epoch:  275  Loss:  tensor(0.7206)\n",
      "Epoch:  276  Loss:  tensor(0.7163)\n",
      "Epoch:  277  Loss:  tensor(0.7305)\n",
      "Epoch:  278  Loss:  tensor(0.7203)\n",
      "Epoch:  279  Loss:  tensor(0.7358)\n",
      "Epoch:  280  Loss:  tensor(0.7275)\n",
      "Epoch:  281  Loss:  tensor(0.7372)\n",
      "Epoch:  282  Loss:  tensor(0.7257)\n",
      "Epoch:  283  Loss:  tensor(0.7295)\n",
      "Epoch:  284  Loss:  tensor(0.7173)\n",
      "Epoch:  285  Loss:  tensor(0.7168)\n",
      "Epoch:  286  Loss:  tensor(0.7036)\n",
      "Epoch:  287  Loss:  tensor(0.7052)\n",
      "Epoch:  288  Loss:  tensor(0.7005)\n",
      "Epoch:  289  Loss:  tensor(0.7045)\n",
      "Epoch:  290  Loss:  tensor(0.7041)\n",
      "Epoch:  291  Loss:  tensor(0.7132)\n",
      "Epoch:  292  Loss:  tensor(0.7110)\n",
      "Epoch:  293  Loss:  tensor(0.7229)\n",
      "Epoch:  294  Loss:  tensor(0.7216)\n",
      "Epoch:  295  Loss:  tensor(0.7357)\n",
      "Epoch:  296  Loss:  tensor(0.7259)\n",
      "Epoch:  297  Loss:  tensor(0.7339)\n",
      "Epoch:  298  Loss:  tensor(0.7217)\n",
      "Epoch:  299  Loss:  tensor(0.7237)\n",
      "Epoch:  300  Loss:  tensor(0.7097)\n",
      "Epoch:  301  Loss:  tensor(0.7116)\n",
      "Epoch:  302  Loss:  tensor(0.7037)\n",
      "Epoch:  303  Loss:  tensor(0.7029)\n",
      "Epoch:  304  Loss:  tensor(0.7027)\n",
      "Epoch:  305  Loss:  tensor(0.7057)\n",
      "Epoch:  306  Loss:  tensor(0.7051)\n",
      "Epoch:  307  Loss:  tensor(0.7128)\n",
      "Epoch:  308  Loss:  tensor(0.7135)\n",
      "Epoch:  309  Loss:  tensor(0.7264)\n",
      "Epoch:  310  Loss:  tensor(0.7224)\n",
      "Epoch:  311  Loss:  tensor(0.7365)\n",
      "Epoch:  312  Loss:  tensor(0.7266)\n",
      "Epoch:  313  Loss:  tensor(0.7352)\n",
      "Epoch:  314  Loss:  tensor(0.7277)\n",
      "Epoch:  315  Loss:  tensor(0.7295)\n",
      "Epoch:  316  Loss:  tensor(0.7189)\n",
      "Epoch:  317  Loss:  tensor(0.7178)\n",
      "Epoch:  318  Loss:  tensor(0.7008)\n",
      "Epoch:  319  Loss:  tensor(0.7033)\n",
      "Epoch:  320  Loss:  tensor(0.6983)\n",
      "Epoch:  321  Loss:  tensor(0.7004)\n",
      "Epoch:  322  Loss:  tensor(0.6986)\n",
      "Epoch:  323  Loss:  tensor(0.7007)\n",
      "Epoch:  324  Loss:  tensor(0.7015)\n",
      "Epoch:  325  Loss:  tensor(0.7055)\n",
      "Epoch:  326  Loss:  tensor(0.7124)\n",
      "Epoch:  327  Loss:  tensor(0.7278)\n",
      "Epoch:  328  Loss:  tensor(0.7192)\n",
      "Epoch:  329  Loss:  tensor(0.7362)\n",
      "Epoch:  330  Loss:  tensor(0.7240)\n",
      "Epoch:  331  Loss:  tensor(0.7315)\n",
      "Epoch:  332  Loss:  tensor(0.7278)\n",
      "Epoch:  333  Loss:  tensor(0.7344)\n",
      "Epoch:  334  Loss:  tensor(0.7208)\n",
      "Epoch:  335  Loss:  tensor(0.7248)\n",
      "Epoch:  336  Loss:  tensor(0.7034)\n",
      "Epoch:  337  Loss:  tensor(0.7110)\n",
      "Epoch:  338  Loss:  tensor(0.7034)\n",
      "Epoch:  339  Loss:  tensor(0.7075)\n",
      "Epoch:  340  Loss:  tensor(0.7074)\n",
      "Epoch:  341  Loss:  tensor(0.7089)\n",
      "Epoch:  342  Loss:  tensor(0.7093)\n",
      "Epoch:  343  Loss:  tensor(0.7185)\n",
      "Epoch:  344  Loss:  tensor(0.7121)\n",
      "Epoch:  345  Loss:  tensor(0.7252)\n",
      "Epoch:  346  Loss:  tensor(0.7175)\n",
      "Epoch:  347  Loss:  tensor(0.7276)\n",
      "Epoch:  348  Loss:  tensor(0.7161)\n",
      "Epoch:  349  Loss:  tensor(0.7215)\n",
      "Epoch:  350  Loss:  tensor(0.7092)\n",
      "Epoch:  351  Loss:  tensor(0.7107)\n",
      "Epoch:  352  Loss:  tensor(0.7033)\n",
      "Epoch:  353  Loss:  tensor(0.7033)\n",
      "Epoch:  354  Loss:  tensor(0.7016)\n",
      "Epoch:  355  Loss:  tensor(0.7015)\n",
      "Epoch:  356  Loss:  tensor(0.7004)\n",
      "Epoch:  357  Loss:  tensor(0.7040)\n",
      "Epoch:  358  Loss:  tensor(0.7060)\n",
      "Epoch:  359  Loss:  tensor(0.7176)\n",
      "Epoch:  360  Loss:  tensor(0.7116)\n",
      "Epoch:  361  Loss:  tensor(0.7272)\n",
      "Epoch:  362  Loss:  tensor(0.7189)\n",
      "Epoch:  363  Loss:  tensor(0.7283)\n",
      "Epoch:  364  Loss:  tensor(0.7295)\n",
      "Epoch:  365  Loss:  tensor(0.7333)\n",
      "Epoch:  366  Loss:  tensor(0.7208)\n",
      "Epoch:  367  Loss:  tensor(0.7243)\n",
      "Epoch:  368  Loss:  tensor(0.6980)\n",
      "Epoch:  369  Loss:  tensor(0.7046)\n",
      "Epoch:  370  Loss:  tensor(0.6952)\n",
      "Epoch:  371  Loss:  tensor(0.6947)\n",
      "Epoch:  372  Loss:  tensor(0.6974)\n",
      "Epoch:  373  Loss:  tensor(0.6883)\n",
      "Epoch:  374  Loss:  tensor(0.6938)\n",
      "Epoch:  375  Loss:  tensor(0.6883)\n",
      "Epoch:  376  Loss:  tensor(0.6919)\n",
      "Epoch:  377  Loss:  tensor(0.6935)\n",
      "Epoch:  378  Loss:  tensor(0.6956)\n",
      "Epoch:  379  Loss:  tensor(0.7115)\n",
      "Epoch:  380  Loss:  tensor(0.7114)\n",
      "Epoch:  381  Loss:  tensor(0.7410)\n",
      "Epoch:  382  Loss:  tensor(0.7131)\n",
      "Epoch:  383  Loss:  tensor(0.6984)\n",
      "Epoch:  384  Loss:  tensor(0.7241)\n",
      "Epoch:  385  Loss:  tensor(0.6915)\n",
      "Epoch:  386  Loss:  tensor(0.6975)\n",
      "Epoch:  387  Loss:  tensor(0.6985)\n",
      "Epoch:  388  Loss:  tensor(0.6901)\n",
      "Epoch:  389  Loss:  tensor(0.7217)\n",
      "Epoch:  390  Loss:  tensor(0.6836)\n",
      "Epoch:  391  Loss:  tensor(0.6770)\n",
      "Epoch:  392  Loss:  tensor(0.6868)\n",
      "Epoch:  393  Loss:  tensor(0.6770)\n",
      "Epoch:  394  Loss:  tensor(0.6853)\n",
      "Epoch:  395  Loss:  tensor(0.6936)\n",
      "Epoch:  396  Loss:  tensor(0.6984)\n",
      "Epoch:  397  Loss:  tensor(0.7395)\n",
      "Epoch:  398  Loss:  tensor(0.7058)\n",
      "Epoch:  399  Loss:  tensor(0.6961)\n",
      "Epoch:  400  Loss:  tensor(0.7317)\n",
      "Epoch:  401  Loss:  tensor(0.7148)\n",
      "Epoch:  402  Loss:  tensor(0.7333)\n",
      "Epoch:  403  Loss:  tensor(0.7834)\n",
      "Epoch:  404  Loss:  tensor(0.6962)\n",
      "Epoch:  405  Loss:  tensor(0.6697)\n",
      "Epoch:  406  Loss:  tensor(0.6719)\n",
      "Epoch:  407  Loss:  tensor(0.6602)\n",
      "Epoch:  408  Loss:  tensor(0.6637)\n",
      "Epoch:  409  Loss:  tensor(0.6652)\n",
      "Epoch:  410  Loss:  tensor(0.6871)\n",
      "Epoch:  411  Loss:  tensor(0.7304)\n",
      "Epoch:  412  Loss:  tensor(0.6962)\n",
      "Epoch:  413  Loss:  tensor(0.6948)\n",
      "Epoch:  414  Loss:  tensor(0.7248)\n",
      "Epoch:  415  Loss:  tensor(0.7427)\n",
      "Epoch:  416  Loss:  tensor(0.7076)\n",
      "Epoch:  417  Loss:  tensor(0.7019)\n",
      "Epoch:  418  Loss:  tensor(0.7104)\n",
      "Epoch:  419  Loss:  tensor(0.7404)\n",
      "Epoch:  420  Loss:  tensor(0.6827)\n",
      "Epoch:  421  Loss:  tensor(0.6694)\n",
      "Epoch:  422  Loss:  tensor(0.6800)\n",
      "Epoch:  423  Loss:  tensor(0.6718)\n",
      "Epoch:  424  Loss:  tensor(0.6840)\n",
      "Epoch:  425  Loss:  tensor(0.6915)\n",
      "Epoch:  426  Loss:  tensor(0.7073)\n",
      "Epoch:  427  Loss:  tensor(0.7534)\n",
      "Epoch:  428  Loss:  tensor(0.7014)\n",
      "Epoch:  429  Loss:  tensor(0.6857)\n",
      "Epoch:  430  Loss:  tensor(0.7179)\n",
      "Epoch:  431  Loss:  tensor(0.6850)\n",
      "Epoch:  432  Loss:  tensor(0.7025)\n",
      "Epoch:  433  Loss:  tensor(0.7352)\n",
      "Epoch:  434  Loss:  tensor(0.6755)\n",
      "Epoch:  435  Loss:  tensor(0.6663)\n",
      "Epoch:  436  Loss:  tensor(0.6697)\n",
      "Epoch:  437  Loss:  tensor(0.6664)\n",
      "Epoch:  438  Loss:  tensor(0.6748)\n",
      "Epoch:  439  Loss:  tensor(0.6881)\n",
      "Epoch:  440  Loss:  tensor(0.7050)\n",
      "Epoch:  441  Loss:  tensor(0.7644)\n",
      "Epoch:  442  Loss:  tensor(0.7109)\n",
      "Epoch:  443  Loss:  tensor(0.6859)\n",
      "Epoch:  444  Loss:  tensor(0.7206)\n",
      "Epoch:  445  Loss:  tensor(0.6850)\n",
      "Epoch:  446  Loss:  tensor(0.6993)\n",
      "Epoch:  447  Loss:  tensor(0.7438)\n",
      "Epoch:  448  Loss:  tensor(0.6786)\n",
      "Epoch:  449  Loss:  tensor(0.6698)\n",
      "Epoch:  450  Loss:  tensor(0.6807)\n",
      "Epoch:  451  Loss:  tensor(0.6732)\n",
      "Epoch:  452  Loss:  tensor(0.6858)\n",
      "Epoch:  453  Loss:  tensor(0.7184)\n",
      "Epoch:  454  Loss:  tensor(0.6849)\n",
      "Epoch:  455  Loss:  tensor(0.6942)\n",
      "Epoch:  456  Loss:  tensor(0.7370)\n",
      "Epoch:  457  Loss:  tensor(0.7771)\n",
      "Epoch:  458  Loss:  tensor(0.7047)\n",
      "Epoch:  459  Loss:  tensor(0.6658)\n",
      "Epoch:  460  Loss:  tensor(0.6743)\n",
      "Epoch:  461  Loss:  tensor(0.6573)\n",
      "Epoch:  462  Loss:  tensor(0.6746)\n",
      "Epoch:  463  Loss:  tensor(0.7142)\n",
      "Epoch:  464  Loss:  tensor(0.6682)\n",
      "Epoch:  465  Loss:  tensor(0.6723)\n",
      "Epoch:  466  Loss:  tensor(0.6877)\n",
      "Epoch:  467  Loss:  tensor(0.6979)\n",
      "Epoch:  468  Loss:  tensor(0.7293)\n",
      "Epoch:  469  Loss:  tensor(0.8030)\n",
      "Epoch:  470  Loss:  tensor(0.7193)\n",
      "Epoch:  471  Loss:  tensor(0.6723)\n",
      "Epoch:  472  Loss:  tensor(0.6955)\n",
      "Epoch:  473  Loss:  tensor(0.6749)\n",
      "Epoch:  474  Loss:  tensor(0.7020)\n",
      "Epoch:  475  Loss:  tensor(0.7085)\n",
      "Epoch:  476  Loss:  tensor(0.7226)\n",
      "Epoch:  477  Loss:  tensor(0.7861)\n",
      "Epoch:  478  Loss:  tensor(0.7054)\n",
      "Epoch:  479  Loss:  tensor(0.6664)\n",
      "Epoch:  480  Loss:  tensor(0.6807)\n",
      "Epoch:  481  Loss:  tensor(0.6618)\n",
      "Epoch:  482  Loss:  tensor(0.6770)\n",
      "Epoch:  483  Loss:  tensor(0.6774)\n",
      "Epoch:  484  Loss:  tensor(0.7049)\n",
      "Epoch:  485  Loss:  tensor(0.7596)\n",
      "Epoch:  486  Loss:  tensor(0.6986)\n",
      "Epoch:  487  Loss:  tensor(0.6734)\n",
      "Epoch:  488  Loss:  tensor(0.7023)\n",
      "Epoch:  489  Loss:  tensor(0.6744)\n",
      "Epoch:  490  Loss:  tensor(0.6927)\n",
      "Epoch:  491  Loss:  tensor(0.7406)\n",
      "Epoch:  492  Loss:  tensor(0.6754)\n",
      "Epoch:  493  Loss:  tensor(0.6695)\n",
      "Epoch:  494  Loss:  tensor(0.6945)\n",
      "Epoch:  495  Loss:  tensor(0.6825)\n",
      "Epoch:  496  Loss:  tensor(0.7111)\n",
      "Epoch:  497  Loss:  tensor(0.7771)\n",
      "Epoch:  498  Loss:  tensor(0.6972)\n",
      "Epoch:  499  Loss:  tensor(0.6632)\n",
      "Epoch:  500  Loss:  tensor(0.6745)\n",
      "Epoch:  501  Loss:  tensor(0.6555)\n",
      "Epoch:  502  Loss:  tensor(0.6794)\n",
      "Epoch:  503  Loss:  tensor(0.7271)\n",
      "Epoch:  504  Loss:  tensor(0.6740)\n",
      "Epoch:  505  Loss:  tensor(0.6776)\n",
      "Epoch:  506  Loss:  tensor(0.7216)\n",
      "Epoch:  507  Loss:  tensor(0.7098)\n",
      "Epoch:  508  Loss:  tensor(0.7574)\n",
      "Epoch:  509  Loss:  tensor(0.8322)\n",
      "Epoch:  510  Loss:  tensor(0.7135)\n",
      "Epoch:  511  Loss:  tensor(0.6704)\n",
      "Epoch:  512  Loss:  tensor(0.6711)\n",
      "Epoch:  513  Loss:  tensor(0.6810)\n",
      "Epoch:  514  Loss:  tensor(0.7493)\n",
      "Epoch:  515  Loss:  tensor(0.7308)\n",
      "Epoch:  516  Loss:  tensor(0.7476)\n",
      "Epoch:  517  Loss:  tensor(0.7581)\n",
      "Epoch:  518  Loss:  tensor(0.6773)\n",
      "Epoch:  519  Loss:  tensor(0.6505)\n",
      "Epoch:  520  Loss:  tensor(0.6490)\n",
      "Epoch:  521  Loss:  tensor(0.6425)\n",
      "Epoch:  522  Loss:  tensor(0.6451)\n",
      "Epoch:  523  Loss:  tensor(0.6408)\n",
      "Epoch:  524  Loss:  tensor(0.6476)\n",
      "Epoch:  525  Loss:  tensor(0.6425)\n",
      "Epoch:  526  Loss:  tensor(0.6555)\n",
      "Epoch:  527  Loss:  tensor(0.6414)\n",
      "Epoch:  528  Loss:  tensor(0.6547)\n",
      "Epoch:  529  Loss:  tensor(0.6521)\n",
      "Epoch:  530  Loss:  tensor(0.6968)\n",
      "Epoch:  531  Loss:  tensor(0.7119)\n",
      "Epoch:  532  Loss:  tensor(0.7936)\n",
      "Epoch:  533  Loss:  tensor(0.8392)\n",
      "Epoch:  534  Loss:  tensor(0.6930)\n",
      "Epoch:  535  Loss:  tensor(0.6531)\n",
      "Epoch:  536  Loss:  tensor(0.6577)\n",
      "Epoch:  537  Loss:  tensor(0.7054)\n",
      "Epoch:  538  Loss:  tensor(0.7916)\n",
      "Epoch:  539  Loss:  tensor(0.7518)\n",
      "Epoch:  540  Loss:  tensor(0.6708)\n",
      "Epoch:  541  Loss:  tensor(0.6492)\n",
      "Epoch:  542  Loss:  tensor(0.6593)\n",
      "Epoch:  543  Loss:  tensor(0.6669)\n",
      "Epoch:  544  Loss:  tensor(0.6929)\n",
      "Epoch:  545  Loss:  tensor(0.7605)\n",
      "Epoch:  546  Loss:  tensor(0.7257)\n",
      "Epoch:  547  Loss:  tensor(0.6603)\n",
      "Epoch:  548  Loss:  tensor(0.6894)\n",
      "Epoch:  549  Loss:  tensor(0.7119)\n",
      "Epoch:  550  Loss:  tensor(0.6663)\n",
      "Epoch:  551  Loss:  tensor(0.6616)\n",
      "Epoch:  552  Loss:  tensor(0.7124)\n",
      "Epoch:  553  Loss:  tensor(0.7582)\n",
      "Epoch:  554  Loss:  tensor(0.6917)\n",
      "Epoch:  555  Loss:  tensor(0.6562)\n",
      "Epoch:  556  Loss:  tensor(0.6842)\n",
      "Epoch:  557  Loss:  tensor(0.6647)\n",
      "Epoch:  558  Loss:  tensor(0.7110)\n",
      "Epoch:  559  Loss:  tensor(0.7755)\n",
      "Epoch:  560  Loss:  tensor(0.7052)\n",
      "Epoch:  561  Loss:  tensor(0.6676)\n",
      "Epoch:  562  Loss:  tensor(0.7045)\n",
      "Epoch:  563  Loss:  tensor(0.7057)\n",
      "Epoch:  564  Loss:  tensor(0.7406)\n",
      "Epoch:  565  Loss:  tensor(0.7647)\n",
      "Epoch:  566  Loss:  tensor(0.6847)\n",
      "Epoch:  567  Loss:  tensor(0.6450)\n",
      "Epoch:  568  Loss:  tensor(0.6531)\n",
      "Epoch:  569  Loss:  tensor(0.6438)\n",
      "Epoch:  570  Loss:  tensor(0.6626)\n",
      "Epoch:  571  Loss:  tensor(0.6849)\n",
      "Epoch:  572  Loss:  tensor(0.7169)\n",
      "Epoch:  573  Loss:  tensor(0.7723)\n",
      "Epoch:  574  Loss:  tensor(0.7258)\n",
      "Epoch:  575  Loss:  tensor(0.6487)\n",
      "Epoch:  576  Loss:  tensor(0.6651)\n",
      "Epoch:  577  Loss:  tensor(0.6809)\n",
      "Epoch:  578  Loss:  tensor(0.6854)\n",
      "Epoch:  579  Loss:  tensor(0.7330)\n",
      "Epoch:  580  Loss:  tensor(0.6937)\n",
      "Epoch:  581  Loss:  tensor(0.6679)\n",
      "Epoch:  582  Loss:  tensor(0.7321)\n",
      "Epoch:  583  Loss:  tensor(0.7187)\n",
      "Epoch:  584  Loss:  tensor(0.6783)\n",
      "Epoch:  585  Loss:  tensor(0.6938)\n",
      "Epoch:  586  Loss:  tensor(0.6649)\n",
      "Epoch:  587  Loss:  tensor(0.6853)\n",
      "Epoch:  588  Loss:  tensor(0.6959)\n",
      "Epoch:  589  Loss:  tensor(0.7210)\n",
      "Epoch:  590  Loss:  tensor(0.7242)\n",
      "Epoch:  591  Loss:  tensor(0.7077)\n",
      "Epoch:  592  Loss:  tensor(0.7043)\n",
      "Epoch:  593  Loss:  tensor(0.7186)\n",
      "Epoch:  594  Loss:  tensor(0.6552)\n",
      "Epoch:  595  Loss:  tensor(0.6469)\n",
      "Epoch:  596  Loss:  tensor(0.6678)\n",
      "Epoch:  597  Loss:  tensor(0.6367)\n",
      "Epoch:  598  Loss:  tensor(0.6483)\n",
      "Epoch:  599  Loss:  tensor(0.6414)\n",
      "Epoch:  600  Loss:  tensor(0.6631)\n",
      "Epoch:  601  Loss:  tensor(0.6456)\n",
      "Epoch:  602  Loss:  tensor(0.6592)\n",
      "Epoch:  603  Loss:  tensor(0.6362)\n",
      "Epoch:  604  Loss:  tensor(0.6437)\n",
      "Epoch:  605  Loss:  tensor(0.6388)\n",
      "Epoch:  606  Loss:  tensor(0.6748)\n",
      "Epoch:  607  Loss:  tensor(0.6187)\n",
      "Epoch:  608  Loss:  tensor(0.6171)\n",
      "Epoch:  609  Loss:  tensor(0.6371)\n",
      "Epoch:  610  Loss:  tensor(0.7294)\n",
      "Epoch:  611  Loss:  tensor(0.9307)\n",
      "Epoch:  612  Loss:  tensor(0.9175)\n",
      "Epoch:  613  Loss:  tensor(0.7373)\n",
      "Epoch:  614  Loss:  tensor(0.6339)\n",
      "Epoch:  615  Loss:  tensor(0.6510)\n",
      "Epoch:  616  Loss:  tensor(0.7017)\n",
      "Epoch:  617  Loss:  tensor(0.7042)\n",
      "Epoch:  618  Loss:  tensor(0.6983)\n",
      "Epoch:  619  Loss:  tensor(0.8180)\n",
      "Epoch:  620  Loss:  tensor(0.7156)\n",
      "Epoch:  621  Loss:  tensor(0.6329)\n",
      "Epoch:  622  Loss:  tensor(0.6374)\n",
      "Epoch:  623  Loss:  tensor(0.6669)\n",
      "Epoch:  624  Loss:  tensor(0.7238)\n",
      "Epoch:  625  Loss:  tensor(0.6934)\n",
      "Epoch:  626  Loss:  tensor(0.6573)\n",
      "Epoch:  627  Loss:  tensor(0.7105)\n",
      "Epoch:  628  Loss:  tensor(0.6951)\n",
      "Epoch:  629  Loss:  tensor(0.7114)\n",
      "Epoch:  630  Loss:  tensor(0.7412)\n",
      "Epoch:  631  Loss:  tensor(0.6931)\n",
      "Epoch:  632  Loss:  tensor(0.6457)\n",
      "Epoch:  633  Loss:  tensor(0.6642)\n",
      "Epoch:  634  Loss:  tensor(0.6360)\n",
      "Epoch:  635  Loss:  tensor(0.6533)\n",
      "Epoch:  636  Loss:  tensor(0.6908)\n",
      "Epoch:  637  Loss:  tensor(0.6614)\n",
      "Epoch:  638  Loss:  tensor(0.6735)\n",
      "Epoch:  639  Loss:  tensor(0.7754)\n",
      "Epoch:  640  Loss:  tensor(0.8034)\n",
      "Epoch:  641  Loss:  tensor(0.6986)\n",
      "Epoch:  642  Loss:  tensor(0.6444)\n",
      "Epoch:  643  Loss:  tensor(0.6740)\n",
      "Epoch:  644  Loss:  tensor(0.7093)\n",
      "Epoch:  645  Loss:  tensor(0.7333)\n",
      "Epoch:  646  Loss:  tensor(0.7140)\n",
      "Epoch:  647  Loss:  tensor(0.7362)\n",
      "Epoch:  648  Loss:  tensor(0.7562)\n",
      "Epoch:  649  Loss:  tensor(0.6777)\n",
      "Epoch:  650  Loss:  tensor(0.6336)\n",
      "Epoch:  651  Loss:  tensor(0.6394)\n",
      "Epoch:  652  Loss:  tensor(0.6361)\n",
      "Epoch:  653  Loss:  tensor(0.6641)\n",
      "Epoch:  654  Loss:  tensor(0.6363)\n",
      "Epoch:  655  Loss:  tensor(0.6623)\n",
      "Epoch:  656  Loss:  tensor(0.6404)\n",
      "Epoch:  657  Loss:  tensor(0.6669)\n",
      "Epoch:  658  Loss:  tensor(0.6319)\n",
      "Epoch:  659  Loss:  tensor(0.6481)\n",
      "Epoch:  660  Loss:  tensor(0.6248)\n",
      "Epoch:  661  Loss:  tensor(0.6416)\n",
      "Epoch:  662  Loss:  tensor(0.6220)\n",
      "Epoch:  663  Loss:  tensor(0.6432)\n",
      "Epoch:  664  Loss:  tensor(0.6180)\n",
      "Epoch:  665  Loss:  tensor(0.6371)\n",
      "Epoch:  666  Loss:  tensor(0.6283)\n",
      "Epoch:  667  Loss:  tensor(0.7127)\n",
      "Epoch:  668  Loss:  tensor(0.8860)\n",
      "Epoch:  669  Loss:  tensor(0.7867)\n",
      "Epoch:  670  Loss:  tensor(0.6359)\n",
      "Epoch:  671  Loss:  tensor(0.6358)\n",
      "Epoch:  672  Loss:  tensor(0.6613)\n",
      "Epoch:  673  Loss:  tensor(0.6472)\n",
      "Epoch:  674  Loss:  tensor(0.6922)\n",
      "Epoch:  675  Loss:  tensor(0.6368)\n",
      "Epoch:  676  Loss:  tensor(0.6658)\n",
      "Epoch:  677  Loss:  tensor(0.6584)\n",
      "Epoch:  678  Loss:  tensor(0.8087)\n",
      "Epoch:  679  Loss:  tensor(0.9014)\n",
      "Epoch:  680  Loss:  tensor(0.7713)\n",
      "Epoch:  681  Loss:  tensor(0.6849)\n",
      "Epoch:  682  Loss:  tensor(0.6658)\n",
      "Epoch:  683  Loss:  tensor(0.6671)\n",
      "Epoch:  684  Loss:  tensor(0.7237)\n",
      "Epoch:  685  Loss:  tensor(0.8310)\n",
      "Epoch:  686  Loss:  tensor(1.0574)\n",
      "Epoch:  687  Loss:  tensor(0.8435)\n",
      "Epoch:  688  Loss:  tensor(0.7048)\n",
      "Epoch:  689  Loss:  tensor(0.6507)\n",
      "Epoch:  690  Loss:  tensor(0.6636)\n",
      "Epoch:  691  Loss:  tensor(0.6771)\n",
      "Epoch:  692  Loss:  tensor(0.7347)\n",
      "Epoch:  693  Loss:  tensor(0.6553)\n",
      "Epoch:  694  Loss:  tensor(0.6412)\n",
      "Epoch:  695  Loss:  tensor(0.6369)\n",
      "Epoch:  696  Loss:  tensor(0.6332)\n",
      "Epoch:  697  Loss:  tensor(0.6315)\n",
      "Epoch:  698  Loss:  tensor(0.6453)\n",
      "Epoch:  699  Loss:  tensor(0.6812)\n",
      "Epoch:  700  Loss:  tensor(0.7547)\n",
      "Epoch:  701  Loss:  tensor(0.7650)\n",
      "Epoch:  702  Loss:  tensor(0.6632)\n",
      "Epoch:  703  Loss:  tensor(0.6937)\n",
      "Epoch:  704  Loss:  tensor(0.7543)\n",
      "Epoch:  705  Loss:  tensor(0.7058)\n",
      "Epoch:  706  Loss:  tensor(0.6541)\n",
      "Epoch:  707  Loss:  tensor(0.6875)\n",
      "Epoch:  708  Loss:  tensor(0.7007)\n",
      "Epoch:  709  Loss:  tensor(0.7287)\n",
      "Epoch:  710  Loss:  tensor(0.7604)\n",
      "Epoch:  711  Loss:  tensor(0.7141)\n",
      "Epoch:  712  Loss:  tensor(0.6428)\n",
      "Epoch:  713  Loss:  tensor(0.6760)\n",
      "Epoch:  714  Loss:  tensor(0.7246)\n",
      "Epoch:  715  Loss:  tensor(0.6638)\n",
      "Epoch:  716  Loss:  tensor(0.6355)\n",
      "Epoch:  717  Loss:  tensor(0.6659)\n",
      "Epoch:  718  Loss:  tensor(0.6923)\n",
      "Epoch:  719  Loss:  tensor(0.7278)\n",
      "Epoch:  720  Loss:  tensor(0.7619)\n",
      "Epoch:  721  Loss:  tensor(0.7313)\n",
      "Epoch:  722  Loss:  tensor(0.6445)\n",
      "Epoch:  723  Loss:  tensor(0.6714)\n",
      "Epoch:  724  Loss:  tensor(0.7276)\n",
      "Epoch:  725  Loss:  tensor(0.6612)\n",
      "Epoch:  726  Loss:  tensor(0.6339)\n",
      "Epoch:  727  Loss:  tensor(0.6640)\n",
      "Epoch:  728  Loss:  tensor(0.6761)\n",
      "Epoch:  729  Loss:  tensor(0.7656)\n",
      "Epoch:  730  Loss:  tensor(0.8038)\n",
      "Epoch:  731  Loss:  tensor(0.7188)\n",
      "Epoch:  732  Loss:  tensor(0.6283)\n",
      "Epoch:  733  Loss:  tensor(0.6327)\n",
      "Epoch:  734  Loss:  tensor(0.6629)\n",
      "Epoch:  735  Loss:  tensor(0.6891)\n",
      "Epoch:  736  Loss:  tensor(0.7272)\n",
      "Epoch:  737  Loss:  tensor(0.7547)\n",
      "Epoch:  738  Loss:  tensor(0.6603)\n",
      "Epoch:  739  Loss:  tensor(0.7030)\n",
      "Epoch:  740  Loss:  tensor(0.7519)\n",
      "Epoch:  741  Loss:  tensor(0.6635)\n",
      "Epoch:  742  Loss:  tensor(0.6302)\n",
      "Epoch:  743  Loss:  tensor(0.6458)\n",
      "Epoch:  744  Loss:  tensor(0.6696)\n",
      "Epoch:  745  Loss:  tensor(0.7650)\n",
      "Epoch:  746  Loss:  tensor(0.7865)\n",
      "Epoch:  747  Loss:  tensor(0.7167)\n",
      "Epoch:  748  Loss:  tensor(0.6224)\n",
      "Epoch:  749  Loss:  tensor(0.6248)\n",
      "Epoch:  750  Loss:  tensor(0.6290)\n",
      "Epoch:  751  Loss:  tensor(0.6668)\n",
      "Epoch:  752  Loss:  tensor(0.7210)\n",
      "Epoch:  753  Loss:  tensor(0.7153)\n",
      "Epoch:  754  Loss:  tensor(0.6580)\n",
      "Epoch:  755  Loss:  tensor(0.7387)\n",
      "Epoch:  756  Loss:  tensor(0.7401)\n",
      "Epoch:  757  Loss:  tensor(0.6647)\n",
      "Epoch:  758  Loss:  tensor(0.6311)\n",
      "Epoch:  759  Loss:  tensor(0.6450)\n",
      "Epoch:  760  Loss:  tensor(0.6224)\n",
      "Epoch:  761  Loss:  tensor(0.6332)\n",
      "Epoch:  762  Loss:  tensor(0.6246)\n",
      "Epoch:  763  Loss:  tensor(0.6446)\n",
      "Epoch:  764  Loss:  tensor(0.6147)\n",
      "Epoch:  765  Loss:  tensor(0.6340)\n",
      "Epoch:  766  Loss:  tensor(0.6095)\n",
      "Epoch:  767  Loss:  tensor(0.6205)\n",
      "Epoch:  768  Loss:  tensor(0.6089)\n",
      "Epoch:  769  Loss:  tensor(0.6340)\n",
      "Epoch:  770  Loss:  tensor(0.6427)\n",
      "Epoch:  771  Loss:  tensor(0.8112)\n",
      "Epoch:  772  Loss:  tensor(0.9489)\n",
      "Epoch:  773  Loss:  tensor(0.8482)\n",
      "Epoch:  774  Loss:  tensor(0.6831)\n",
      "Epoch:  775  Loss:  tensor(0.6459)\n",
      "Epoch:  776  Loss:  tensor(0.6763)\n",
      "Epoch:  777  Loss:  tensor(0.6924)\n",
      "Epoch:  778  Loss:  tensor(0.7947)\n",
      "Epoch:  779  Loss:  tensor(0.6874)\n",
      "Epoch:  780  Loss:  tensor(0.6584)\n",
      "Epoch:  781  Loss:  tensor(0.6446)\n",
      "Epoch:  782  Loss:  tensor(0.6464)\n",
      "Epoch:  783  Loss:  tensor(0.7220)\n",
      "Epoch:  784  Loss:  tensor(0.7899)\n",
      "Epoch:  785  Loss:  tensor(0.7190)\n",
      "Epoch:  786  Loss:  tensor(0.6303)\n",
      "Epoch:  787  Loss:  tensor(0.6568)\n",
      "Epoch:  788  Loss:  tensor(0.7343)\n",
      "Epoch:  789  Loss:  tensor(0.7495)\n",
      "Epoch:  790  Loss:  tensor(0.6779)\n",
      "Epoch:  791  Loss:  tensor(0.7316)\n",
      "Epoch:  792  Loss:  tensor(0.7770)\n",
      "Epoch:  793  Loss:  tensor(0.6836)\n",
      "Epoch:  794  Loss:  tensor(0.6245)\n",
      "Epoch:  795  Loss:  tensor(0.6367)\n",
      "Epoch:  796  Loss:  tensor(0.6761)\n",
      "Epoch:  797  Loss:  tensor(0.7175)\n",
      "Epoch:  798  Loss:  tensor(0.7443)\n",
      "Epoch:  799  Loss:  tensor(0.7741)\n",
      "Epoch:  800  Loss:  tensor(0.7114)\n",
      "Epoch:  801  Loss:  tensor(0.6311)\n",
      "Epoch:  802  Loss:  tensor(0.6431)\n",
      "Epoch:  803  Loss:  tensor(0.6334)\n",
      "Epoch:  804  Loss:  tensor(0.6806)\n",
      "Epoch:  805  Loss:  tensor(0.6902)\n",
      "Epoch:  806  Loss:  tensor(0.6906)\n",
      "Epoch:  807  Loss:  tensor(0.8234)\n",
      "Epoch:  808  Loss:  tensor(0.7845)\n",
      "Epoch:  809  Loss:  tensor(0.6345)\n",
      "Epoch:  810  Loss:  tensor(0.6221)\n",
      "Epoch:  811  Loss:  tensor(0.6309)\n",
      "Epoch:  812  Loss:  tensor(0.6106)\n",
      "Epoch:  813  Loss:  tensor(0.6253)\n",
      "Epoch:  814  Loss:  tensor(0.6129)\n",
      "Epoch:  815  Loss:  tensor(0.6511)\n",
      "Epoch:  816  Loss:  tensor(0.7363)\n",
      "Epoch:  817  Loss:  tensor(0.8008)\n",
      "Epoch:  818  Loss:  tensor(0.8390)\n",
      "Epoch:  819  Loss:  tensor(0.7140)\n",
      "Epoch:  820  Loss:  tensor(0.6546)\n",
      "Epoch:  821  Loss:  tensor(0.7057)\n",
      "Epoch:  822  Loss:  tensor(0.6265)\n",
      "Epoch:  823  Loss:  tensor(0.6165)\n",
      "Epoch:  824  Loss:  tensor(0.6253)\n",
      "Epoch:  825  Loss:  tensor(0.6524)\n",
      "Epoch:  826  Loss:  tensor(0.6930)\n",
      "Epoch:  827  Loss:  tensor(0.7792)\n",
      "Epoch:  828  Loss:  tensor(0.7697)\n",
      "Epoch:  829  Loss:  tensor(0.6371)\n",
      "Epoch:  830  Loss:  tensor(0.6322)\n",
      "Epoch:  831  Loss:  tensor(0.6873)\n",
      "Epoch:  832  Loss:  tensor(0.6456)\n",
      "Epoch:  833  Loss:  tensor(0.6647)\n",
      "Epoch:  834  Loss:  tensor(0.7914)\n",
      "Epoch:  835  Loss:  tensor(0.7179)\n",
      "Epoch:  836  Loss:  tensor(0.6208)\n",
      "Epoch:  837  Loss:  tensor(0.6521)\n",
      "Epoch:  838  Loss:  tensor(0.6662)\n",
      "Epoch:  839  Loss:  tensor(0.7476)\n",
      "Epoch:  840  Loss:  tensor(0.7978)\n",
      "Epoch:  841  Loss:  tensor(0.6693)\n",
      "Epoch:  842  Loss:  tensor(0.6485)\n",
      "Epoch:  843  Loss:  tensor(0.7026)\n",
      "Epoch:  844  Loss:  tensor(0.6357)\n",
      "Epoch:  845  Loss:  tensor(0.6323)\n",
      "Epoch:  846  Loss:  tensor(0.6964)\n",
      "Epoch:  847  Loss:  tensor(0.6576)\n",
      "Epoch:  848  Loss:  tensor(0.7530)\n",
      "Epoch:  849  Loss:  tensor(0.8273)\n",
      "Epoch:  850  Loss:  tensor(0.7382)\n",
      "Epoch:  851  Loss:  tensor(0.6311)\n",
      "Epoch:  852  Loss:  tensor(0.6092)\n",
      "Epoch:  853  Loss:  tensor(0.6221)\n",
      "Epoch:  854  Loss:  tensor(0.6803)\n",
      "Epoch:  855  Loss:  tensor(0.7800)\n",
      "Epoch:  856  Loss:  tensor(0.8064)\n",
      "Epoch:  857  Loss:  tensor(0.6587)\n",
      "Epoch:  858  Loss:  tensor(0.6380)\n",
      "Epoch:  859  Loss:  tensor(0.6765)\n",
      "Epoch:  860  Loss:  tensor(0.6192)\n",
      "Epoch:  861  Loss:  tensor(0.6300)\n",
      "Epoch:  862  Loss:  tensor(0.7116)\n",
      "Epoch:  863  Loss:  tensor(0.7125)\n",
      "Epoch:  864  Loss:  tensor(0.7531)\n",
      "Epoch:  865  Loss:  tensor(0.7506)\n",
      "Epoch:  866  Loss:  tensor(0.6540)\n",
      "Epoch:  867  Loss:  tensor(0.6255)\n",
      "Epoch:  868  Loss:  tensor(0.6537)\n",
      "Epoch:  869  Loss:  tensor(0.6338)\n",
      "Epoch:  870  Loss:  tensor(0.6979)\n",
      "Epoch:  871  Loss:  tensor(0.7705)\n",
      "Epoch:  872  Loss:  tensor(0.7053)\n",
      "Epoch:  873  Loss:  tensor(0.6226)\n",
      "Epoch:  874  Loss:  tensor(0.6563)\n",
      "Epoch:  875  Loss:  tensor(0.7222)\n",
      "Epoch:  876  Loss:  tensor(0.7217)\n",
      "Epoch:  877  Loss:  tensor(0.6500)\n",
      "Epoch:  878  Loss:  tensor(0.7099)\n",
      "Epoch:  879  Loss:  tensor(0.7653)\n",
      "Epoch:  880  Loss:  tensor(0.6815)\n",
      "Epoch:  881  Loss:  tensor(0.6282)\n",
      "Epoch:  882  Loss:  tensor(0.6612)\n",
      "Epoch:  883  Loss:  tensor(0.6957)\n",
      "Epoch:  884  Loss:  tensor(0.7676)\n",
      "Epoch:  885  Loss:  tensor(0.7430)\n",
      "Epoch:  886  Loss:  tensor(0.6300)\n",
      "Epoch:  887  Loss:  tensor(0.6141)\n",
      "Epoch:  888  Loss:  tensor(0.6243)\n",
      "Epoch:  889  Loss:  tensor(0.6174)\n",
      "Epoch:  890  Loss:  tensor(0.6434)\n",
      "Epoch:  891  Loss:  tensor(0.6364)\n",
      "Epoch:  892  Loss:  tensor(0.7207)\n",
      "Epoch:  893  Loss:  tensor(0.7614)\n",
      "Epoch:  894  Loss:  tensor(0.6727)\n",
      "Epoch:  895  Loss:  tensor(0.6174)\n",
      "Epoch:  896  Loss:  tensor(0.6287)\n",
      "Epoch:  897  Loss:  tensor(0.6066)\n",
      "Epoch:  898  Loss:  tensor(0.6148)\n",
      "Epoch:  899  Loss:  tensor(0.6144)\n",
      "Epoch:  900  Loss:  tensor(0.6604)\n",
      "Epoch:  901  Loss:  tensor(0.7161)\n",
      "Epoch:  902  Loss:  tensor(0.7588)\n",
      "Epoch:  903  Loss:  tensor(0.7763)\n",
      "Epoch:  904  Loss:  tensor(0.6583)\n",
      "Epoch:  905  Loss:  tensor(0.6170)\n",
      "Epoch:  906  Loss:  tensor(0.6297)\n",
      "Epoch:  907  Loss:  tensor(0.6112)\n",
      "Epoch:  908  Loss:  tensor(0.6199)\n",
      "Epoch:  909  Loss:  tensor(0.6126)\n",
      "Epoch:  910  Loss:  tensor(0.6227)\n",
      "Epoch:  911  Loss:  tensor(0.5889)\n",
      "Epoch:  912  Loss:  tensor(0.5884)\n",
      "Epoch:  913  Loss:  tensor(0.5900)\n",
      "Epoch:  914  Loss:  tensor(0.6153)\n",
      "Epoch:  915  Loss:  tensor(0.6192)\n",
      "Epoch:  916  Loss:  tensor(0.8397)\n",
      "Epoch:  917  Loss:  tensor(0.9860)\n",
      "Epoch:  918  Loss:  tensor(0.8701)\n",
      "Epoch:  919  Loss:  tensor(0.7104)\n",
      "Epoch:  920  Loss:  tensor(0.6836)\n",
      "Epoch:  921  Loss:  tensor(0.7379)\n",
      "Epoch:  922  Loss:  tensor(0.6589)\n",
      "Epoch:  923  Loss:  tensor(0.6847)\n",
      "Epoch:  924  Loss:  tensor(0.6812)\n",
      "Epoch:  925  Loss:  tensor(0.7379)\n",
      "Epoch:  926  Loss:  tensor(0.6679)\n",
      "Epoch:  927  Loss:  tensor(0.6408)\n",
      "Epoch:  928  Loss:  tensor(0.6511)\n",
      "Epoch:  929  Loss:  tensor(0.6886)\n",
      "Epoch:  930  Loss:  tensor(0.6752)\n",
      "Epoch:  931  Loss:  tensor(0.7342)\n",
      "Epoch:  932  Loss:  tensor(0.7042)\n",
      "Epoch:  933  Loss:  tensor(0.6894)\n",
      "Epoch:  934  Loss:  tensor(0.7372)\n",
      "Epoch:  935  Loss:  tensor(0.8179)\n",
      "Epoch:  936  Loss:  tensor(0.7273)\n",
      "Epoch:  937  Loss:  tensor(0.6503)\n",
      "Epoch:  938  Loss:  tensor(0.6381)\n",
      "Epoch:  939  Loss:  tensor(0.6558)\n",
      "Epoch:  940  Loss:  tensor(0.6670)\n",
      "Epoch:  941  Loss:  tensor(0.7258)\n",
      "Epoch:  942  Loss:  tensor(0.7088)\n",
      "Epoch:  943  Loss:  tensor(0.6910)\n",
      "Epoch:  944  Loss:  tensor(0.7531)\n",
      "Epoch:  945  Loss:  tensor(0.8158)\n",
      "Epoch:  946  Loss:  tensor(0.7110)\n",
      "Epoch:  947  Loss:  tensor(0.6390)\n",
      "Epoch:  948  Loss:  tensor(0.6377)\n",
      "Epoch:  949  Loss:  tensor(0.6596)\n",
      "Epoch:  950  Loss:  tensor(0.6505)\n",
      "Epoch:  951  Loss:  tensor(0.6878)\n",
      "Epoch:  952  Loss:  tensor(0.6908)\n",
      "Epoch:  953  Loss:  tensor(0.7381)\n",
      "Epoch:  954  Loss:  tensor(0.7358)\n",
      "Epoch:  955  Loss:  tensor(0.7018)\n",
      "Epoch:  956  Loss:  tensor(0.7038)\n",
      "Epoch:  957  Loss:  tensor(0.7505)\n",
      "Epoch:  958  Loss:  tensor(0.6712)\n",
      "Epoch:  959  Loss:  tensor(0.6332)\n",
      "Epoch:  960  Loss:  tensor(0.6338)\n",
      "Epoch:  961  Loss:  tensor(0.6314)\n",
      "Epoch:  962  Loss:  tensor(0.6533)\n",
      "Epoch:  963  Loss:  tensor(0.7141)\n",
      "Epoch:  964  Loss:  tensor(0.6610)\n",
      "Epoch:  965  Loss:  tensor(0.6611)\n",
      "Epoch:  966  Loss:  tensor(0.7201)\n",
      "Epoch:  967  Loss:  tensor(0.7915)\n",
      "Epoch:  968  Loss:  tensor(0.7108)\n",
      "Epoch:  969  Loss:  tensor(0.6338)\n",
      "Epoch:  970  Loss:  tensor(0.6390)\n",
      "Epoch:  971  Loss:  tensor(0.6765)\n",
      "Epoch:  972  Loss:  tensor(0.6573)\n",
      "Epoch:  973  Loss:  tensor(0.7047)\n",
      "Epoch:  974  Loss:  tensor(0.6995)\n",
      "Epoch:  975  Loss:  tensor(0.7178)\n",
      "Epoch:  976  Loss:  tensor(0.7554)\n",
      "Epoch:  977  Loss:  tensor(0.7677)\n",
      "Epoch:  978  Loss:  tensor(0.6640)\n",
      "Epoch:  979  Loss:  tensor(0.6270)\n",
      "Epoch:  980  Loss:  tensor(0.6344)\n",
      "Epoch:  981  Loss:  tensor(0.6153)\n",
      "Epoch:  982  Loss:  tensor(0.6120)\n",
      "Epoch:  983  Loss:  tensor(0.6044)\n",
      "Epoch:  984  Loss:  tensor(0.6051)\n",
      "Epoch:  985  Loss:  tensor(0.6037)\n",
      "Epoch:  986  Loss:  tensor(0.6162)\n",
      "Epoch:  987  Loss:  tensor(0.5930)\n",
      "Epoch:  988  Loss:  tensor(0.6151)\n",
      "Epoch:  989  Loss:  tensor(0.6261)\n",
      "Epoch:  990  Loss:  tensor(0.8989)\n",
      "Epoch:  991  Loss:  tensor(1.0671)\n",
      "Epoch:  992  Loss:  tensor(0.9061)\n",
      "Epoch:  993  Loss:  tensor(0.7648)\n",
      "Epoch:  994  Loss:  tensor(0.6883)\n",
      "Epoch:  995  Loss:  tensor(0.6920)\n",
      "Epoch:  996  Loss:  tensor(0.6966)\n",
      "Epoch:  997  Loss:  tensor(0.7778)\n",
      "Epoch:  998  Loss:  tensor(0.6613)\n",
      "Epoch:  999  Loss:  tensor(0.6407)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000): # 200 epochs\n",
    "    prediction = net(x)    \n",
    "    loss = loss_func(prediction, y)\n",
    "    print(\"Epoch: \", i, \" Loss: \", loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
